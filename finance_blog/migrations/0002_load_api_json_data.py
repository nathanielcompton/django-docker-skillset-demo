# Generated by Django 3.0.3 on 2020-02-17 19:11
import os
import json
import logging
from django.db import migrations

logger = logging.getLogger(__name__)


def add_api_data(apps, schema_editor):
    """
    This Django data migration file is primarily to showcase the framework's internal
    ETL and db interaction capabality. The interview project's evaluation criteria
    mentions database use, so this highlights specifically Django + PostgreSQL.

    1. Open relevant .json files, and parse out required data
    2. Get models from versioned app registry (i.e. we need historical versioning)
    3. Assign that data to instances of our previously-created Django models
    4. Save those instances to the db (i.e. creating rows in PostgreSQL tables)
    """
    CONTENT_API_FILE = "finance_blog/docs/content_api.json"
    QUOTES_API_FILE = "finance_blog/docs/quotes_api.json"
    Author = apps.get_model("finance_blog", "Author")
    Article = apps.get_model("finance_blog", "Article")
    Quote = apps.get_model("finance_blog", "Quote")
    if os.path.exists(CONTENT_API_FILE) and os.path.exists(QUOTES_API_FILE):
        try:
            with open(CONTENT_API_FILE) as f:
                content_api_data = json.load(f)
                # This logic depends on the structure of the JSON object
                # provided for the interview project.
                for i in content_api_data["results"]:
                    if not Author.objects.filter(uuid=i["authors"][0]["uuid"]).exists():
                        Author.objects.get_or_create(
                            uuid=i["authors"][0]["uuid"],  # Only 1st author for demo.
                            username=i["authors"][0]["username"],
                            byline=i["authors"][0]["byline"],
                            contributor_type=i["authors"][0]["contributor_type"],
                            email=i["authors"][0]["email"],
                            first_name=i["authors"][0]["first_name"],
                            last_name=i["authors"][0]["last_name"],
                            fool_uid=i["authors"][0]["fool_uid"],
                            primary=i["authors"][0]["primary"],
                            small_avatar_url=i["authors"][0]["small_avatar_url"],
                            large_avatar_url=i["authors"][0]["large_avatar_url"],
                            twitter_username=i["authors"][0]["twitter_username"],
                            short_bio=i["authors"][0]["short_bio"],
                            long_bio=i["authors"][0]["long_bio"],
                        )
                    # This assumes there will always be a `featured` image.
                    # TODO: Add a conditional check, or move it into `Image` table.
                    featured_image = [pic for pic in i["images"] if pic["featured"]]
                    Article.objects.create(
                        uuid=i["uuid"],
                        body=i["body"],
                        headline=i["headline"],
                        promo=i["promo"],
                        byline=i["authors"][0]["byline"],
                        article_type=i["article_type"],
                        featured_image_url=featured_image[0]["url"],
                        featured_image_name=featured_image[0]["name"],
                        static_page=i["static_page"],
                        path=i["path"],  # TODO: This should be dynamically generated.
                        created=i["created"],
                        publish_at=i["publish_at"],
                        modified=i["modified"],
                        disclosure=i["disclosure"],
                    )

            with open(QUOTES_API_FILE) as g:
                quotes_api_data = json.load(g)
                for i in quotes_api_data:
                    if not Quote.objects.filter(
                        symbol=i["Symbol"],
                        exchange=i["Exchange"],
                        last_trade_date=i["LastTradeDate"],
                    ):
                        Quote.objects.create(
                            company_name=i["CompanyName"],
                            symbol=i["Symbol"],
                            exchange=i["Exchange"],
                            currency_code=i["CurrencyCode"],
                            description=i["Description"],
                            current_price=i["CurrentPrice"]["Amount"],
                            change=i["Change"]["Amount"],
                            percent_change=i["PercentChange"]["Value"],
                            website=i["Website"],
                            last_trade_date=i["LastTradeDate"],
                        )
        except IOError as e:
            logger.exception(f"IOError during data migration attempt!", e)
    else:
        raise IOError(
            f"JSON files for data migration not found, or incorrect permissions."
        )


def remove_api_data(apps, schema_editor):
    """
    The 'rollback' function to remove any unwanted instances created by add_api_data().
    """
    Author = apps.get_model("finance_blog", "Author")
    Article = apps.get_model("finance_blog", "Article")
    Quote = apps.get_model("finance_blog", "Quote")
    Author.objects.all().delete()
    Article.objects.all().delete()
    Quote.objects.all().delete()


class Migration(migrations.Migration):

    dependencies = [
        ("finance_blog", "0001_initial"),
    ]

    operations = [
        migrations.RunPython(add_api_data, remove_api_data),
    ]
